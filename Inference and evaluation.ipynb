{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as t\n",
    "import tensorflow as tf\n",
    "\n",
    "import importlib\n",
    "#importlib.reload(t)\n",
    "\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "import evaluation as e\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "#Exact_match and token_accuracy is adapted from the evaluation file\n",
    "# in the tutorial on Neural Machine Translation: https://github.com/tensorflow/nmt\n",
    "\n",
    "def exact_match(labels, predictions, max_token_check=None):\n",
    "    #\"\"\"Compute exact match\"\"\"\n",
    "    match = 0.0\n",
    "    count = 0.0\n",
    "    if max_token_check == None:\n",
    "        max_token_check = 1000\n",
    "    for idx in range(len(labels)):\n",
    "        if np.all(labels[idx][:max_token_check] == predictions[idx][:max_token_check]):\n",
    "            match += 1\n",
    "\n",
    "        count += 1\n",
    "    return 100 * match / count\n",
    "\n",
    "\n",
    "def token_accuracy(labels, predictions, max_token_check=None):\n",
    "    #\"\"\"Compute accuracy on per word basis.\"\"\"\n",
    "    total_acc, total_count = 0., 0.\n",
    "    if max_token_check==None:\n",
    "        m_length = 1000\n",
    "    else:\n",
    "        m_length = max_token_check\n",
    "\n",
    "    for idx, target_sentence in enumerate(labels):\n",
    "        prediction = predictions[idx]\n",
    "\n",
    "        match = 0.0\n",
    "\n",
    "        total_count += 1 \n",
    "        for pos in range(min(len(target_sentence), len(prediction), m_length)):\n",
    "            label = target_sentence[pos]\n",
    "            pred = prediction[pos]\n",
    "            if label == pred:\n",
    "                match += 1\n",
    "        \n",
    "             \n",
    "        if max_token_check==None:\n",
    "            total_acc += 100 * match / max(len(target_sentence), len(prediction))\n",
    "        else:\n",
    "            total_acc += 100 * match / min(len(target_sentence), len(prediction), m_length)\n",
    "            \n",
    "    return total_acc / total_count\n",
    "\n",
    "\n",
    "def lev_dist(labels, predictions, max_token_check=None):\n",
    "    \n",
    "    avg_distance = 0\n",
    "    count = 0.0\n",
    "  \n",
    "    for idx in range(len(labels)):\n",
    "\n",
    "        if max_token_check is not None:\n",
    "            lev_distance = distance.levenshtein(labels[idx][:max_token_check], predictions[idx][:max_token_check])\n",
    "            lev_distance = lev_distance / (min(len(labels[idx]), max_token_check))\n",
    "        else:\n",
    "            lev_distance = distance.levenshtein(labels[idx], predictions[idx])\n",
    "            lev_distance = lev_distance / (len(labels[idx]))\n",
    "\n",
    "        avg_distance = avg_distance + lev_distance\n",
    "        count += 1\n",
    "\n",
    "    avg_distance = float(avg_distance) / count\n",
    "    return avg_distance\n",
    "\n",
    "\n",
    "def get_metrics(labels, predictions, max_token_check=None):\n",
    "    exact_match_avg = exact_match(labels, predictions, max_token_check)\n",
    "    token_accuracy_avg = token_accuracy(labels, predictions, max_token_check)\n",
    "    edit_distance_avg = lev_dist(labels, predictions, max_token_check)\n",
    "    return exact_match_avg, token_accuracy_avg, edit_distance_avg\n",
    "\n",
    "\n",
    "def get_token_seq(int_sequence):\n",
    "    \n",
    "    output = []\n",
    "    for value in int_sequence:\n",
    "        output.append(reverse_target_token_index[value])\n",
    "        if reverse_target_token_index[value] == \"**end**\":\n",
    "            break\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocabulary\n",
    "token_vocabulary = [\"**end**\", \"**start**\", \"**unknown**\"]\n",
    "\n",
    "token_vocabulary.extend(t.get_vocabulary(\"train\"))\n",
    "\n",
    "target_tokens = token_vocabulary  # TODO: Refactor this. Currently duplicate naming\n",
    "\n",
    "token_vocab_size = len(target_tokens)\n",
    "# todo: document what was lifted from tutorials and what we wrote ourselves\n",
    "target_token_index = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_target_token_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n ======================= Loading Data =======================\")\n",
    "#new cell\n",
    "\n",
    "train_dataset = t.get_data_somehow('train', True, t.hparams['mini_batch_size'], t.hparams['max_token_length'], t.hparams['max_train_num_samples'] , target_token_index)\n",
    "val_dataset = t.get_data_somehow('val', True, t.hparams['mini_batch_size'], t.hparams['max_token_length'], t.hparams['max_val_num_samples'], target_token_index)\n",
    "\n",
    "train_encoder_input_data_batches = train_dataset[0]\n",
    "train_target_texts_batches = train_dataset[1]\n",
    "train_sequence_lengths_batches = train_dataset[2]\n",
    "train_decoder_input_data_batches = train_dataset[3]\n",
    "train_decoder_target_data_batches = train_dataset[4]\n",
    "\n",
    "val_encoder_input_data_batches = val_dataset[0]\n",
    "val_target_texts_batches = val_dataset[1]\n",
    "val_sequence_lengths_batches = val_dataset[2]\n",
    "val_decoder_input_data_batches = val_dataset[3]\n",
    "val_decoder_target_data_batches = val_dataset[4]\n",
    "print(\"\\n ======================= Data Loaded =======================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "embedding_decoder, decoder_cell, decoder_initial_state, projection_layer, img \\\n",
    "= t.create_graph(token_vocab_size, t.hparams['num_units'], t.hparams['use_attention'], t.hparams['use_encoding_average_as_initial_state'], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "checkpoint = \"model_8.ckpt\"\n",
    "\n",
    "ON_FLOYDHUB = True\n",
    "\n",
    "if ON_FLOYDHUB:\n",
    "    t.initialize_variables(sess, restore=True, path='/checkpoints/checkpoints/model_8.ckpt')\n",
    "else:\n",
    "    t.initialize_variables(sess, restore=True, path='../output/checkpoints/' + checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_and_labels(evaluation_images, evaluation_ground_truth, beam_size):    \n",
    "    \n",
    "    predictions = []\n",
    "    labels = []    \n",
    "\n",
    "    print(\"Evaluating \" + str(len(evaluation_images)) + \" batches in the \" + EVALUATION_SET + \" set\")\n",
    "    for idx, batch in enumerate(evaluation_images):\n",
    "\n",
    "\n",
    "        if idx == 400:\n",
    "            break\n",
    "\n",
    "        if beam_size == 1:\n",
    "            output, logits = t.predict_batch(sess,\n",
    "                          batch,\n",
    "                          target_token_index,\n",
    "                          embedding_decoder,\n",
    "                          decoder_cell,\n",
    "                          decoder_initial_state,\n",
    "                          projection_layer,\n",
    "                          img)\n",
    "        else:\n",
    "            output, logits = t.predict_batch_beam(sess,\n",
    "                          batch,\n",
    "                          target_token_index,\n",
    "                          embedding_decoder,\n",
    "                          decoder_cell,\n",
    "                          encoder_state,\n",
    "                          projection_layer,\n",
    "                          img,\n",
    "                          beam_size=beam_size)\n",
    "\n",
    "        if idx % 20 == 0:\n",
    "            print(\"Progress: \" + str(idx) + \" batches\")\n",
    "\n",
    "        for idy in range(output.shape[0]):\n",
    "            prediction = get_token_seq(output[idy,:])\n",
    "            predictions.append(prediction[:-1])\n",
    "            labels.append(evaluation_ground_truth[idx][idy].split()[1:])\n",
    "        \n",
    "    return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_SET = \"VAL\"\n",
    "if EVALUATION_SET == \"VAL\":\n",
    "    evaluation_images = val_encoder_input_data_batches\n",
    "    evaluation_ground_truth = val_target_texts_batches\n",
    "elif EVALUATION_SET == \"TRAIN\":\n",
    "    evaluation_images = train_encoder_input_data_batches\n",
    "    evaluation_ground_truth = train_target_texts_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1, labels = get_predictions_and_labels(evaluation_images, evaluation_ground_truth, beam_size=1)\n",
    "metrics1 = get_metrics(labels, predictions)\n",
    "print(metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_loss():\n",
    "    #num_val_batches = len(val_sequence_lengths_batches)\n",
    "    val_loss = 0    \n",
    "    for i in range(num_val_batches):\n",
    "        input_data = {img: val_encoder_input_data_batches[i],\n",
    "                                        decoder_lengths: val_sequence_lengths_batches[i],\n",
    "                                         decoder_inputs: val_decoder_input_data_batches[i],\n",
    "                                          decoder_outputs: val_decoder_target_data_batches[i],\n",
    "                                         }\n",
    "   \n",
    "        output_tensors = [train_loss]\n",
    "        loss = sess.run(output_tensors, \n",
    "                               feed_dict=input_data)\n",
    "        \n",
    "        print(loss)\n",
    "        val_loss = val_loss + loss[0]\n",
    "        \n",
    "    val_loss = val_loss / len(val_decoder_input_data_batches[i])\n",
    "    return val_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
