{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning images of equations into LateX: The Pipeline Approach\n",
    "##### Adam Jensen and Henrik Marklund"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Import keras modules\n",
    "from keras import optimizers, metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "#Import our own functions\n",
    "import load_data\n",
    "import helper_functions as hf\n",
    "import segment_helper_functions as seg_hf\n",
    "import recursive_profile_cutting as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTHON_VERSION = \"PYTHON2\"\n",
    "\n",
    "\n",
    "\n",
    "if PYTHON_VERSION == \"PYTHON2\":\n",
    "    reload(load_data)\n",
    "    reload(hf)\n",
    "    reload(seg_hf)\n",
    "    reload(rpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hparams = {}\n",
    "hparams['model'] = \"BASELINE\" #\"BASELINE\", \"CONVNET1\", \"CONVNET2\"\n",
    "hparams['augmented_data'] = True\n",
    "hparams['crop_width'] = 30\n",
    "hparams['crop_height'] = 35\n",
    "hparams['dsample_factor'] = 0.6\n",
    "\n",
    "hparams['epochs'] = 20\n",
    "\n",
    "\n",
    "hparams['load_from_pickle'] = False\n",
    "hparams['save_to_pickle'] = False # Currently super slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset INFTY-CDB 3 (images of math symbsols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Max width: ', 120)\n",
      "('Min width: ', 5)\n",
      "('Mean width: ', 35.558135254894744)\n",
      "('Max height: ', 188)\n",
      "('Min heigh: ', 2)\n",
      "('Mean height: ', 47.714696263997624)\n",
      "('Number of examples: ', 70637)\n",
      "Math symbols loaded\n"
     ]
    }
   ],
   "source": [
    "if hparams['load_from_pickle']:\n",
    "    data_pickle = pickle.load( open( \"data_pickle.p\", \"rb\" ) )\n",
    "    X = data_pickle['X']\n",
    "    Y = data_pickle['Y']\n",
    "    num_unique = data_pickle['num_unique']\n",
    "    target_token_index = data_pickle['target_token_index']  \n",
    "else:\n",
    "    X, Y, num_unique, target_token_index = load_data.load_math_symbols()\n",
    "    if hparams['save_to_pickle']:\n",
    "        data_pickle = {'X': X, 'Y': Y, 'num_unique': num_unique, 'target_token_index': target_token_index}\n",
    "        pickle.dump( data_pickle, open( \"data_pickle.p\", \"wb\" ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_token_index = dict(\n",
    "    (i, token) for token, i in target_token_index.items())\n",
    "\n",
    "orig_shape = (X.shape[1], X.shape[2])\n",
    "X, Y = hf.shuffle_data(X,Y, seed=100)\n",
    "\n",
    "hex_to_token_dict = load_data.get_hex_to_token_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down sample images\n",
    "\n",
    "X_small = hf.down_sample(X, hparams['dsample_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split up to train/val set and test set\n",
    "\n",
    "Y = np_utils.to_categorical(Y, num_classes = num_unique)\n",
    "\n",
    "X_train = X_small[:56509]\n",
    "X_val = X_small[56509:(56509+7063)]\n",
    "X_test = X_small[(56509+7063):]\n",
    "\n",
    "Y_train = Y[:56509]\n",
    "Y_val = Y[56509:(56509+7063)]\n",
    "Y_test = Y[(56509+7063):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X,Y, num_k):\n",
    "    shift = 0.05\n",
    "    zoom = 0.1\n",
    "    shear = 0.2\n",
    "    datagen = ImageDataGenerator(zoom_range=zoom, width_shift_range=shift, height_shift_range=shift)\n",
    "    #datagen = ImageDataGenerator(zoom_range=zoom)\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
    "    X_augmented = X\n",
    "    Y_augmented = Y\n",
    "    \n",
    "    # fit parameters from data\n",
    "    datagen.fit(X)\n",
    "    # Configure batch size and retrieve one batch of images\n",
    "\n",
    "    counter = 0\n",
    "    \n",
    "    for X_batch, y_batch in datagen.flow(X, Y, batch_size=1000):\n",
    "        # Show 9 images\n",
    "        \n",
    "        \n",
    "        if counter == 0:\n",
    "            for i in range(0, 9):\n",
    "                plt.subplot(330 + 1 + i)\n",
    "                plt.imshow(np.squeeze(X_batch[i]), cmap='gray')\n",
    "            # show the plot\n",
    "            plt.show()\n",
    "        \n",
    "        X_augmented = np.concatenate((X_augmented, X_batch), axis=0)\n",
    "        Y_augmented = np.concatenate((Y_augmented, y_batch), axis=0)\n",
    "        \n",
    "        counter = counter + 1\n",
    "        \n",
    "        if counter % 10 == 0:\n",
    "            print(\"Progress: \" + str(counter) + \"/ \" + str(num_k))\n",
    "        \n",
    "        if counter == num_k:\n",
    "            break\n",
    "    \n",
    "    return X_augmented, Y_augmented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAD8CAYAAAAG730QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0JlQUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11abf4890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_augmented shape: ', (56509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (57509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (58509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (59509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (60509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (61509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (62509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (63509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (64509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (65509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (66509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (67509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (68509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (69509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (70509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (71509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (72509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (73509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (74509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (75509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (76509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (77509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (78509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (79509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (80509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (81509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (82509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (83509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (84509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (85509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (86509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (87509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (88509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (89509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (90509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (91509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (92509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (93509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (94509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (95509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (96509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (97509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (98509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (99509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (100509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (101509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (102509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (103509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (104509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (105509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (106509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (107509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (108509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (109509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (110509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (111509, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (112509, 113, 72, 1))\n",
      "('X_batch shape: ', (509, 113, 72, 1))\n",
      "('Y batch shape: ', (509, 275))\n",
      "('X_augmented shape: ', (113018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (114018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (115018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (116018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (117018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (118018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (119018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (120018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (121018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (122018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (123018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (124018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (125018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_augmented shape: ', (126018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (127018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (128018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (129018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (130018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (131018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (132018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (133018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (134018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (135018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (136018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (137018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (138018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (139018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (140018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (141018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (142018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (143018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (144018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (145018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (146018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (147018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (148018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (149018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (150018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (151018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (152018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (153018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (154018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n",
      "('X_augmented shape: ', (155018, 113, 72, 1))\n",
      "('X_batch shape: ', (1000, 113, 72, 1))\n",
      "('Y batch shape: ', (1000, 275))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if hparams['augmented_data']:\n",
    "    X_train_non_augmented = X_train\n",
    "    Y_train_non_augmented = Y_train\n",
    "    \n",
    "    X_train, Y_train = augment_data(X_train,Y_train, 100)\n",
    "    \n",
    "    \n",
    "X_train, Y_train = hf.shuffle_data(X_train,Y_train, seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d2ba684acd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = hf.crop_images(X_test, hparams['crop_width'], hparams['crop_height'])\n",
    "X_val = hf.crop_images(X_val, hparams['crop_width'], hparams['crop_height'])\n",
    "X_train = hf.crop_images(X_train, hparams['crop_width'], hparams['crop_height'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAD8CAYAAABuOagBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQEEEv0/tUIxkxe7788AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x52678bd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(X_train[132323]), cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize and invert\n",
    "X_test_normalized = hf.normalize_and_invert(X_test)\n",
    "X_val_normalized = hf.normalize_and_invert(X_val)\n",
    "X_train_normalized = hf.normalize_and_invert(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshape images depending on model\n",
    "\n",
    "\n",
    "if hparams['model'] == \"BASELINE\":\n",
    "\n",
    "    X_train_vecs = hf.flatten(X_train_normalized)\n",
    "    X_val_vecs = hf.flatten(X_val_normalized)\n",
    "    X_test_vecs = hf.flatten(X_test_normalized)\n",
    "\n",
    "#If we are using a convnet\n",
    "else:\n",
    "    X_train_vecs = hf.add_dimension(X_train_normalized)\n",
    "    X_val_vecs = hf.add_dimension(X_val_normalized)\n",
    "    X_test_vecs = hf.add_dimension(X_test_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Y_train.shape[0] == X_train_vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELS adapated from https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "num_pixels = X_train_vecs.shape[1]\n",
    "num_classes = Y_test.shape[1]\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def convnet1(image_size):\n",
    "    \n",
    "    height = image_size[0]\n",
    "    width = image_size[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(height, width, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def convnet2(image_size):\n",
    "    \n",
    "    height = image_size[0]\n",
    "    width = image_size[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(height, width, 1), activation='relu'))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BASELINE\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "\n",
    "if hparams['model'] == \"BASELINE\":\n",
    "    print(\"Training BASELINE\")\n",
    "    model = baseline_model()\n",
    "elif hparams['model'] == \"CONVNET1\":\n",
    "    print(\"Training CONVNET1\")\n",
    "    model = convnet1((hparams['crop_height'], hparams['crop_width']))\n",
    "elif hparams['model'] == \"CONVNET2\":\n",
    "    model = convnet2((hparams['crop_height'], hparams['crop_width']))\n",
    "# Fit the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # OBS: Learning rate is set with a callback instead (see next cell)\n",
    "beta_1 = 0.9 # Keras default\n",
    "beta_2 = 0.999 # Keras default\n",
    "epsilon=1e-08 # Keras default\n",
    "decay=1e-6 # \n",
    "\n",
    "adam_optimizer = optimizers.Adam(lr=learning_rate,\n",
    "                                       beta_1=beta_1,\n",
    "                                       beta_2=beta_2, \n",
    "                                       epsilon=epsilon,\n",
    "                                       decay=decay)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156018 samples, validate on 7063 samples\n",
      "Epoch 1/5\n",
      " - 38s - loss: 0.8310 - acc: 0.8088 - val_loss: 0.1242 - val_acc: 0.9717\n",
      "Epoch 2/5\n",
      " - 39s - loss: 0.2396 - acc: 0.9347 - val_loss: 0.0938 - val_acc: 0.9778\n",
      "Epoch 3/5\n",
      " - 39s - loss: 0.1500 - acc: 0.9571 - val_loss: 0.0858 - val_acc: 0.9816\n",
      "Epoch 4/5\n",
      " - 39s - loss: 0.1106 - acc: 0.9669 - val_loss: 0.0784 - val_acc: 0.9846\n",
      "Epoch 5/5\n",
      " - 40s - loss: 0.0939 - acc: 0.9721 - val_loss: 0.0644 - val_acc: 0.9864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fit_history = model.fit(X_train_vecs, Y_train, validation_data=(X_val_vecs, Y_val), epochs=hparams['epochs'], batch_size=200, verbose=2)\n",
    "# Final evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test_vecs, Y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.visualize_training_history(fit_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 31, 26, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 13, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 11, 15)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 5, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 450)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               57728     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 275)               14025     \n",
      "=================================================================\n",
      "Total params: 83,048\n",
      "Trainable params: 83,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# between 80k and 1.5 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEGMENTING EQUATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Equation dataset\n",
    "\n",
    "equation_images = load_data.load_equations(40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.imshow(equation_images[39], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_segmented_equation(equation_image, smaller_images, show_each_symbol=False):\n",
    "\n",
    "\n",
    "    backtorgb = np.copy(equation_image)\n",
    "    plt.imshow(equation_image, cmap='gray')\n",
    "\n",
    "    for image_with_position in smaller_images:\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        smaller_image = image_with_position['image']\n",
    "        smaller_image_shape = image_with_position['image'].shape\n",
    "\n",
    "        corner1y = image_with_position['position'][0]\n",
    "        corner1x = image_with_position['position'][1]\n",
    "        corner1 = (corner1x, corner1y)\n",
    "\n",
    "        corner2y = corner1y + smaller_image_shape[0] - 1\n",
    "        corner2x = corner1x + smaller_image_shape[1]\n",
    "\n",
    "        corner2 = (corner2x, corner2y) # x, y\n",
    "\n",
    "        cv2.rectangle(backtorgb,corner1,corner2,(0,255,0),2)\n",
    "\n",
    "\n",
    "        if show_each_symbol:\n",
    "            \n",
    "            print(\"Predicted token: \", image_with_position['predicted_token'])\n",
    "            plt.imshow(smaller_image, cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    plt.imshow(backtorgb, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smaller_images[0].shape\n",
    "\n",
    "#padded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40 35\n",
    "\n",
    "ta_size = orig_shape\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_for_predict(smaller_images, orig_shape, down_sample_symbol=True):\n",
    "    padded_images = hf.pad_images(smaller_images, orig_shape)\n",
    "\n",
    "    if down_sample_symbol:\n",
    "        down_sampled_images = hf.down_sample(padded_images,hparams['dsample_factor'])\n",
    "\n",
    "        h = down_sampled_images.shape[1]\n",
    "        w = down_sampled_images.shape[2]\n",
    "    else:\n",
    "        h = padded_images.shape[1]\n",
    "        w = padded_images.shape[2]\n",
    "\n",
    "    h_start = int(h / 2 - hparams['crop_height'] / 2)\n",
    "    w_start = int(w / 2 - hparams['crop_width'] / 2)\n",
    "\n",
    "\n",
    "    if down_sample_symbol:\n",
    "        final_images = down_sampled_images[:, h_start:h_start+hparams['crop_height'], w_start:w_start+hparams['crop_width']]\n",
    "    else:\n",
    "        final_images = padded_images[:, h_start:h_start+hparams['crop_height'], w_start:w_start+hparams['crop_width']]\n",
    "\n",
    "    \n",
    "    return final_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#image_to_predict = np.reshape(X_train[611], (1, X_train[611].shape[0]*X_train[611].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_step_before_predict(final_images):\n",
    "    images_to_predict = np.reshape(final_images, (final_images.shape[0], final_images.shape[1]*final_images.shape[2]))\n",
    "    images_to_predict = 255 - images_to_predict\n",
    "    images_to_predict = images_to_predict.astype('float')\n",
    "    images_to_predict = images_to_predict / 255.0\n",
    "    return images_to_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_smaller_images(images, orig_shape, down_sample_symbol=True):\n",
    "\n",
    "    \n",
    "    images_with_positions = images\n",
    "\n",
    "    smaller_images = seg_hf.get_just_images(images)\n",
    "    \n",
    "    final_images = preprocess_images_for_predict(smaller_images, orig_shape, down_sample_symbol)\n",
    "    images_to_predict = last_step_before_predict(final_images)\n",
    "    output = model.predict(images_to_predict)\n",
    "    tokenids = np.argmax(output, axis=1)\n",
    "    #print(len(tokenids))\n",
    "    \n",
    "    for idx, o in enumerate(tokenids):\n",
    "        hexa = reverse_target_token_index[o]\n",
    "\n",
    "        token = hex_to_token_dict[hexa]\n",
    "        #real_output.append([token, o])\n",
    "        images[idx]['predicted_token_id'] = o\n",
    "\n",
    "        images[idx]['id'] = idx\n",
    "        images[idx]['predicted_token'] = token\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learned this from: https://stackoverflow.com/questions/8242832/python-all-possible-pairs-of-2-list-elements-and-getting-the-index-of-that-pair\n",
    "import itertools\n",
    "def all_pairs(lst):\n",
    "    for p in itertools.combinations(lst,2):\n",
    "        i = iter(p)\n",
    "        yield zip(i,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_equal_sign(image_1,image_2):\n",
    "    predicted1 = image_1['predicted_token']\n",
    "    predicted2 = image_2['predicted_token']\n",
    "    \n",
    "    if predicted1 != 'minus' or predicted2 != 'minus':\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    w1 = image_1['image'].shape[1]\n",
    "    w2 = image_2['image'].shape[1]\n",
    "    \n",
    "    cx1 = seg_hf.get_center_from_image(image_1)[1]\n",
    "    cx2 = seg_hf.get_center_from_image(image_2)[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if np.abs(w1-w2) > 4:\n",
    "        return False\n",
    "    if np.abs(cx1 - cx2) > 4:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_lc_i(image_1,image_2):\n",
    "    predicted1 = image_1['predicted_token']\n",
    "    predicted2 = image_2['predicted_token']\n",
    "    \n",
    "    top_symbols = ['comma', 'prime', 'ast']\n",
    "    bottom_symbols = ['one', 'l', 'i', 'iota']\n",
    "    \n",
    "    w1 = image_1['image'].shape[1]\n",
    "    w2 = image_2['image'].shape[1]\n",
    "    \n",
    "    cx1 = seg_hf.get_center_from_image(image_1)[1]\n",
    "    cx2 = seg_hf.get_center_from_image(image_2)[1]\n",
    "    \n",
    "    if np.abs(w1-w2) > 15:\n",
    "        return False\n",
    "    if np.abs(cx1 - cx2) > 15:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    if is_on_top(image_1, image_2):\n",
    "        if (predicted1 in top_symbols and predicted2 in bottom_symbols):\n",
    "            return True\n",
    "    elif is_on_top(image_2, image_1):\n",
    "        if (predicted1 in bottom_symbols and predicted2 in top_symbols):\n",
    "            return True\n",
    "    \n",
    "    \n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Works\n",
    "\n",
    "def is_on_top(image_1, image_2):\n",
    "    centery1, centerx1 = seg_hf.get_center_from_image(image_1)\n",
    "    centery2, centerx2 = seg_hf.get_center_from_image(image_2)\n",
    "    \n",
    "    if centery1 < centery2:\n",
    "        \n",
    "        return True\n",
    "    elif centery1 >= centery2:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_images(image_1, image_2):\n",
    "    \n",
    "    if is_on_top(image_1, image_2):\n",
    "        print(\"Is on top\")\n",
    "        new_y1 = image_1['position'][0]\n",
    "        new_x1 = min(image_1['position'][1],image_2['position'][1])\n",
    "        \n",
    "        yoffset = image_2['position'][0] - image_1['position'][0] - image_1['image'].shape[0]\n",
    "        \n",
    "        image_2_height = image_2['image'].shape[0]\n",
    "        image_2_width = image_2['image'].shape[1]\n",
    "        \n",
    "        image_1_height = image_1['image'].shape[0]\n",
    "        image_1_width = image_1['image'].shape[1]\n",
    "        \n",
    "        new_height = image_1_height + image_2_height + yoffset\n",
    "        new_width = max(image_1_width, image_2_width)\n",
    "        \n",
    "        new_image = 255 * np.ones((new_height, new_width))\n",
    "        \n",
    "        new_image[:image_1_height, :image_1_width] = image_1['image']\n",
    "        new_image[image_1_height+yoffset:, :image_2_width] = image_2['image']\n",
    "    else:\n",
    "        new_y1 = image_2['position'][0]\n",
    "        new_x1 = min(image_1['position'][1],image_2['position'][1])\n",
    "\n",
    "        yoffset = image_1['position'][0] - image_2['position'][0] - image_2['image'].shape[0]\n",
    "        image_2_height = image_2['image'].shape[0]\n",
    "        image_2_width = image_2['image'].shape[1]\n",
    "        \n",
    "        image_1_height = image_1['image'].shape[0]\n",
    "        image_1_width = image_1['image'].shape[1]\n",
    "        \n",
    "        new_height = image_1_height + image_2_height + yoffset\n",
    "        new_width = max(image_1_width, image_2_width)\n",
    "        \n",
    "        new_image = 255 * np.ones((new_height, new_width))\n",
    "\n",
    "        \n",
    "        new_image[:image_2_height, :image_2_width] = image_2['image']\n",
    "        print(\"new_height: \", new_height)\n",
    "        print(\"yoffset: \", yoffset)\n",
    "        print(\"image_1 shape\", image_1['image'].shape)\n",
    "        new_image[image_2_height+yoffset:, :image_1_width] = image_1['image']\n",
    "    \n",
    "    \n",
    "    new_image_with_position = {}\n",
    "    new_image_with_position['image'] = new_image\n",
    "    new_image_with_position['position'] = (new_y1, new_x1)\n",
    "    \n",
    "    \n",
    "    return new_image_with_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_lc_is(images):\n",
    "    ids_to_remove = []\n",
    "    \n",
    "    new_predicted_images = []\n",
    "    new_list = all_pairs(images)\n",
    "    \n",
    "    lower_case_is = []\n",
    "    \n",
    "    for pair in new_list:\n",
    "        \n",
    "        if PYTHON_VERSION == \"PYTHON3\":\n",
    "            pair = list(pair)\n",
    "        \n",
    "        image_1 = pair[0][0]\n",
    "        image_2 = pair[0][1]\n",
    "        #print(image_1['id'])\n",
    "        #print(image_2['id'])\n",
    "        if check_if_lc_i(image_1,image_2):\n",
    "            new_image = concat_images(image_1, image_2)\n",
    "            #print(\"found one equal sign\")\n",
    "            ids_to_remove.append(image_1['id'])\n",
    "            ids_to_remove.append(image_2['id'])\n",
    "\n",
    "            new_image['id'] = image_1['id']\n",
    "            new_image['predicted_token'] = 'i'\n",
    "            lower_case_is.append(new_image)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for image in images:\n",
    "        if image['id'] not in ids_to_remove:\n",
    "            new_predicted_images.append(image)\n",
    "    \n",
    "    for lower_case_i in lower_case_is:\n",
    "        new_predicted_images.append(lower_case_i)\n",
    "    \n",
    "    return new_predicted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_equal_signs(images):\n",
    "    ids_to_remove = []\n",
    "    \n",
    "    new_predicted_images = []\n",
    "    \n",
    "    equal_signs = []\n",
    "    new_list = all_pairs(images)\n",
    "    for pair in new_list:\n",
    "        \n",
    "        if PYTHON_VERSION == \"PYTHON3\":\n",
    "            pair = list(pair)\n",
    "            \n",
    "        image_1 = pair[0][0]\n",
    "        image_2 = pair[0][1]\n",
    "\n",
    "        if check_if_equal_sign(image_1,image_2):\n",
    "            new_image = concat_images(image_1, image_2)\n",
    "            #print(\"found one equal sign\")\n",
    "            ids_to_remove.append(image_1['id'])\n",
    "            ids_to_remove.append(image_2['id'])\n",
    "\n",
    "            \n",
    "            new_image['id'] = image_1['id']\n",
    "            new_image['predicted_token'] = 'equal'\n",
    "            equal_signs.append(new_image)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for image in images:\n",
    "        if image['id'] not in ids_to_remove:\n",
    "            new_predicted_images.append(image)\n",
    "    \n",
    "    for equal_sign in equal_signs:\n",
    "        new_predicted_images.append(equal_sign)\n",
    "    \n",
    "    return new_predicted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rules(predicted_images):\n",
    "    images_processed = find_equal_signs(predicted_images)\n",
    "    images_processed = find_lc_is(images_processed)\n",
    "    \n",
    "    return images_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_list = all_pairs(predicted_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_area(image_with_position):\n",
    "    image_shape = image_with_position['image'].shape\n",
    "    return image_shape[0] * image_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def segment_and_apply_rules(equation_image, orig_shape):\n",
    "\n",
    "\n",
    "    img_with_positions = rpc.segment_equation(equation_image)\n",
    "    show_segmented_equation(equation_image, img_with_positions)\n",
    "\n",
    "    predicted_images = predict_smaller_images(img_with_positions, orig_shape)\n",
    "    rules_applied = apply_rules(predicted_images)\n",
    "\n",
    "    show_segmented_equation(equation_image, rules_applied)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_position(image_1, image_2, properties):\n",
    "    image1_shape = image_1['image'].shape\n",
    "    image2_shape = image_2['image'].shape\n",
    "    \n",
    "    if len(properties) > 0:\n",
    "        last_property = properties[-1]\n",
    "    else:\n",
    "        last_property = (None, None)\n",
    "    \n",
    "    image1_h = image1_shape[0]\n",
    "    image2_h = image2_shape[0]\n",
    "    \n",
    "    positiony1 = image_1['position'][0]\n",
    "    positionx1 = image_1['position'][1]\n",
    "    \n",
    "    positiony2 = image_2['position'][0]\n",
    "    positionx2 = image_2['position'][1]\n",
    "    \n",
    "    centery1, centerx1 = seg_hf.get_center_from_image(image_1)\n",
    "    centery2, centerx2 = seg_hf.get_center_from_image(image_2) \n",
    "    \n",
    "    # Below, above, sup or sub\n",
    "    \n",
    "    if last_property[0] == \"SUBRIGHT\":\n",
    "        if positiony2 < last_property[1] + 3:\n",
    "            properties.pop()\n",
    "            return (\"PREVIOUS\", properties)\n",
    "        \n",
    "    if last_property[0] == \"SUPRIGHT\":\n",
    "        if positiony2 + image2_h > last_property[1] - 3:\n",
    "            properties.pop()\n",
    "            return (\"PREVIOUS\", properties)\n",
    "    \n",
    "    if image2_h < image1_h:\n",
    "        ## Below\n",
    "        if (centerx2 > positionx1) and centerx2 < positionx1+image1_shape[1] and positiony2 > positiony1 + image1_shape[0]:\n",
    "            return (\"BELOW\", properties)\n",
    "\n",
    "        ## Above\n",
    "        if centerx2 > positionx1 and centerx2 < positionx1+image1_shape[1] and positiony2 + image2_shape[0] < positiony1:\n",
    "            return (\"ABOVE\", properties)\n",
    "\n",
    "\n",
    "        ## Subscript right\n",
    "        if centerx1 < positionx2 and positiony2 > centery1:\n",
    "            properties.append((\"SUBRIGHT\", centery1))\n",
    "            return (\"SUBRIGHT\", properties)\n",
    "\n",
    "        ## Superscript right\n",
    "        if centerx1 < positionx2 and positiony2+image2_shape[0] < centery1:\n",
    "            properties.append((\"SUPRIGHT\", centery1))\n",
    "            return (\"SUPRIGHT\", properties)\n",
    "        \n",
    "    ## To the right\n",
    "    return (\"RIGHT\", properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for imgg in rules_applied:\n",
    "    #plt.imshow(imgg['image'])\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_images(images):\n",
    "    newlist = sorted(images, key=lambda k: k['id']) \n",
    "    return newlist\n",
    "\n",
    "def structural_analysis_and_latex(images):\n",
    "\n",
    "    images = sort_images(images)\n",
    "\n",
    "    latex_string = \"\"\n",
    "    prop = []\n",
    "    for idx in range(len(images)):\n",
    "        if idx == len(images) - 1:\n",
    "            latex = seg_hf.get_latex(images[idx]['predicted_token'])\n",
    "            latex_string += \" \" + latex\n",
    "            if len(prop) != 0:\n",
    "                latex_string += \" }\"\n",
    "            break\n",
    "\n",
    "\n",
    "        rel_pos, props = get_relative_position(images[idx], images[idx+1], prop)\n",
    "        prop = props\n",
    "\n",
    "\n",
    "        latex = seg_hf.get_latex(images[idx]['predicted_token'])\n",
    "\n",
    "        latex_string += \" \" + latex\n",
    "        if rel_pos == \"SUBRIGHT\":\n",
    "            latex_string += \"_{\"\n",
    "        elif rel_pos == \"PREVIOUS\":\n",
    "            latex_string += \" }\"\n",
    "        elif rel_pos ==\"SUPRIGHT\":\n",
    "            latex_string += \"^{\"\n",
    "        #print(rel_pos)\n",
    "    \n",
    "    return latex_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_latex(equation_image, show_segmentation=False, show_each_symbol=False, down_sample_symbol=True):\n",
    "    img_with_positions = rpc.segment_equation(equation_image)\n",
    "    predicted_images = predict_smaller_images(img_with_positions, orig_shape, down_sample_symbol)\n",
    "    rules_applied = apply_rules(predicted_images)\n",
    "    if show_segmentation:\n",
    "        ims= sort_images(rules_applied)\n",
    "        show_segmented_equation(equation_image, ims, show_each_symbol=show_each_symbol)\n",
    "    return structural_analysis_and_latex(rules_applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABxCAYAAADbEGjnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsZibhBVsNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x53be6a650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABxCAYAAADbEGjnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK5wTvZlZ4ZzozcwK50RvZla4/wcE+4+F3osCpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x52673f9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \\succeq \\otimes < >^{ \\preceq } \\preceq \\succeq \\otimes < z X\n"
     ]
    }
   ],
   "source": [
    "print(image_to_latex(equation_image, show_segmentation=True, show_each_symbol=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "print(latex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in rules_applied:\n",
    "    plt.imshow(img['image'], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_applied\n",
    "\n",
    "pairs_of_images = all_pairs(rules_applied)\n",
    "\n",
    "# edge (id1, id2, )\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
