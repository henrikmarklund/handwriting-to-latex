{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning Equations into LaTeX using an attention based seq2seq model\n",
    "CS230<br>\n",
    "Adam Jensen, Henrik Marklund<br>\n",
    "oojensen@stanford.edu, marklund@stanford.edu<br>\n",
    "\n",
    "### 1. Background\n",
    "We were typing up our CS229 homework and realized that we were spending more time on LaTeX than the actual homework. We did a quick informal survey amongst students in the Huang basement who concurred: yes, typesetting is a major inconvenience! Many said they spent over 5 and 10 hours per homework in CS221 and CS229 respectively. Another typical response was: “I chose not to typeset on the last CS229 homework, as I did not have time”.<br>\n",
    "\n",
    "There is currently no good solution for converting handwritten notes into LateX. As a consequence, STEM students around the world struggle. The long term goal is to train an algorithm that takes a scan of your a4 page and turns it into latex typesetting. <br>\n",
    "\n",
    "We limit the scope of this project to:\n",
    "- Create a seq-to-seq model with attention turning images of digital equations into latex. <br>\n",
    "\n",
    "This is also a request-for-research at OpenAI: https://openai.com/requests-for-research/#im2latex \n",
    "\n",
    "\n",
    "### 2. Dataset\n",
    "Harvard Researchers have crawled wikipedia for mathematical equations and gathered a 100k equations from which one can generate images. Dataset: Harvard im-to-latex-100k (Described in __[Deng et al., 2016](https://arxiv.org/pdf/1609.04938.pdf)__) Guilluame Genthial at Stanford was kind enough to send us his generated images (as this takes quite some time). We do some additional processing (padding, and additional downsampling).\n",
    "\n",
    "Here is an example image with corresponding latex:\n",
    "\n",
    "\n",
    "__Latex__:\n",
    "\\widetilde \\gamma \\_ { \\mathrm { h o p f } } \\simeq \\sum \\_ { n > 0 } \\widetilde { G } \\_ { n } { \\frac { ( - a ) ^ { n } } { 2 ^ { 2 n - 1 } } }\n",
    "\n",
    "##### Histogram: Sequence lengths\n",
    "\n",
    "When running the code you will see more examples and more details about the dataset.\n",
    "\n",
    "### 3. Progress through the projeect (sequential):\n",
    "\n",
    "__1. Dataset loaded and processed.__ <br>\n",
    "We have approx 80k images with corresponding latex loaded and preprocessed. For now we skip looking at too long sentences and too big images.<br><br>\n",
    "__2. Encoder-Decoder model up and running in Keras.__ <br>\n",
    "__3. Overfit to 10 examples__<br>\n",
    "After introducing Batch Normalization we managed to overfit to 10 examples. At this point, still hard to overfit to many more examples.\n",
    "__4. Training with decreasing loss on 40k images / sequences__ <br>\n",
    "Training is really slow which makes it important that we are systematic and smart about our experiments going forward.\n",
    "Implemented Clip Gradient and a Learning rate schedule.<br><br>\n",
    "__5. For debugging: Created an analogous but less complex problem.__ <br>\n",
    "Since it was hard to know why it was so hard overfitting to a larger number of examples we created a simpler but analogous problem: turning pictures of text into text (but treating each character as a separate token to keep the problem analogous). Training was a lot easier, and we could much more easily overfit on a larger number training examples.\n",
    "__6. Switched to TensorFlow and the Seq2seq library.__ <br>\n",
    "__7. Got the Keras model to work without attention.__ <br>\n",
    "__8. Got the Tensorflow model with attention to work improving accuracy by a lot.__ <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 4. The model\n",
    "\n",
    "#### Overview\n",
    "Our model is based on a typical seq-to-seq model for translation. We started out with a seq-to-seq model for translation in Keras using LSTM (__[Described by Francois Chollet](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html)__. We replaced the encoder with a convolution neural network as described by in the paper __[Image to Latex by Genthial & Sauvestre (2016)](http://cs231n.stanford.edu/reports/2017/pdfs/815.pdf)__. The conv. network design is one of the versions __[here](https://github.com/guillaumegenthial/im2latex/blob/master/model/encoder.py)__. We have one model for training and one model for inference (using the weights from the first model).<br><br>\n",
    "\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "\n",
    "#### Decoder\n",
    "\n",
    "\n",
    "##### Without attention\n",
    "\n",
    "\n",
    "##### With attention\n",
    "Embedding Size: 80\n",
    "\n",
    "\n",
    "#### Greedy vs. Beam Search\n",
    "\n",
    "### 5. Training\n",
    "\n",
    "#### Learning Schedule\n",
    "<img src=\"model_visualizations/learning_rate_schedule.jpg\" height=\"40%\" width=\"40%\" alt=\"Learning rate schedule\" title=\"Learning rate\" />\n",
    "\n",
    "#### Other parameters\n",
    "Mini-batch size:\n",
    "Gradient clipping: \n",
    "\n",
    "\n",
    "### 6. Results\n",
    "\n",
    "#### Experiments\n",
    "\n",
    "\n",
    "#### Example predictions\n",
    "\n",
    "\n",
    "#### Error analysis\n",
    "\n",
    "#### Visualizing the attention\n",
    "\n",
    "\n",
    "### 7. Next steps\n",
    "\n",
    "\n",
    "\n",
    "### 8. References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
